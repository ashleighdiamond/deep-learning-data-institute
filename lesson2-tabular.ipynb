{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this notebook comes from this kaggle [competition](https://www.kaggle.com/c/wids2018datathon/). You are given a dataset of survey questions and results from a developing country. Your goal is to predict the gender of the respondent based on the other answers he/she provided. You Kaggle api to get the data. All variables in this dataset and categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install kaggle` <br/>\n",
    "\n",
    "`kaggle competitions download -c wids2018datathon -p /data/yinterian/WiDS18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"/Users/yinterian/teaching/deeplearning/data/WiDS18/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  \\\n",
       "0         0    3   32  3.0  NaN  323011  3854   481  1975          1   \n",
       "1         1    2   26  NaN  8.0  268131  2441   344  1981          1   \n",
       "2         2    1   16  NaN  7.0  167581   754   143  1995          1   \n",
       "3         3    4   44  5.0  NaN  445071  5705   604  1980          1   \n",
       "4         4    4   43  NaN  6.0  436161  5645   592  1958          1   \n",
       "\n",
       "      ...       GN1  GN1_OTHERS GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  \\\n",
       "0     ...      99.0         NaN  99         NaN   99         NaN   99   \n",
       "1     ...       NaN         NaN   1         NaN    2         NaN    2   \n",
       "2     ...       1.0         NaN   2         NaN    2         NaN    2   \n",
       "3     ...       NaN         NaN   2         NaN    2         NaN   99   \n",
       "4     ...       NaN         NaN   1         NaN    1         NaN    1   \n",
       "\n",
       "   GN4_OTHERS  GN5  GN5_OTHERS  \n",
       "0         NaN   99         NaN  \n",
       "1         NaN    2         NaN  \n",
       "2         NaN    2         NaN  \n",
       "3         NaN   99         NaN  \n",
       "4         NaN    1         NaN  \n",
       "\n",
       "[5 rows x 1235 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(PATH/\"train.csv\", low_memory=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18255, 1235)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  DG3     ...      \\\n",
       "0    3   32  3.0  NaN  323011  3854   481  1975          1    3     ...       \n",
       "1    2   26  NaN  8.0  268131  2441   344  1981          1    8     ...       \n",
       "2    1   16  NaN  7.0  167581   754   143  1995          1    3     ...       \n",
       "3    4   44  5.0  NaN  445071  5705   604  1980          1    3     ...       \n",
       "4    4   43  NaN  6.0  436161  5645   592  1958          1    3     ...       \n",
       "\n",
       "    GN1 GN1_OTHERS  GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0  99.0        NaN   99         NaN   99         NaN   99         NaN   99   \n",
       "1   NaN        NaN    1         NaN    2         NaN    2         NaN    2   \n",
       "2   1.0        NaN    2         NaN    2         NaN    2         NaN    2   \n",
       "3   NaN        NaN    2         NaN    2         NaN   99         NaN   99   \n",
       "4   NaN        NaN    1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1234 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train id looks like a unique id for each row\n",
    "train = train.drop(columns=[\"train_id\"])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning columns with too many NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12602"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"AA5\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AA3                     0\n",
       "AA4                     0\n",
       "AA5                 12602\n",
       "AA6                  5653\n",
       "AA7                     0\n",
       "AA14                    0\n",
       "AA15                    0\n",
       "DG1                     0\n",
       "is_female               0\n",
       "DG3                     0\n",
       "DG3A                    0\n",
       "DG3A_OTHERS         18205\n",
       "DG4                     0\n",
       "DG4_OTHERS          18255\n",
       "DG5_1                   0\n",
       "DG5_2                   0\n",
       "DG5_3                   0\n",
       "DG5_4                   0\n",
       "DG5_5                   0\n",
       "DG5_6                   0\n",
       "DG5_7                   0\n",
       "DG5_8                   0\n",
       "DG5_9                   0\n",
       "DG5_10                  0\n",
       "DG5_11                  0\n",
       "DG5_96                  0\n",
       "DG6                     0\n",
       "DG8a                    0\n",
       "DG8b                    0\n",
       "DG8c                    0\n",
       "                    ...  \n",
       "FB28_2_OTHERS       18253\n",
       "FB28_3_OTHERS       18255\n",
       "FB28_4_OTHERS       18253\n",
       "FB28_96_OTHERS      18254\n",
       "FB29_1                  0\n",
       "FB29_2                  0\n",
       "FB29_3                  0\n",
       "FB29_4                  0\n",
       "FB29_5                  0\n",
       "FB29_6                  0\n",
       "FB29_96                 0\n",
       "FB29_OTHERS         18189\n",
       "LN1A                    0\n",
       "LN1B                    0\n",
       "LN2_1                   0\n",
       "LN2_2                   0\n",
       "LN2_3                   0\n",
       "LN2_4                   0\n",
       "LN2_RIndLngBEOth     6914\n",
       "LN2_WIndLngBEOth     6911\n",
       "GN1                  4025\n",
       "GN1_OTHERS          18196\n",
       "GN2                     0\n",
       "GN2_OTHERS          18177\n",
       "GN3                     0\n",
       "GN3_OTHERS          18172\n",
       "GN4                     0\n",
       "GN4_OTHERS          18169\n",
       "GN5                     0\n",
       "GN5_OTHERS          18179\n",
       "Length: 1234, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the number of NULL in per column\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping columns with too many nulls\n",
    "for col in train.columns:\n",
    "    if train[col].isnull().sum() > 12000:\n",
    "        #print(col, train[col].isnull().sum())\n",
    "        train.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA6     AA7  AA14  AA15   DG1  is_female  DG3  DG3A ...   LN2_2  \\\n",
       "0    3   32  NaN  323011  3854   481  1975          1    3     4 ...       1   \n",
       "1    2   26  8.0  268131  2441   344  1981          1    8     4 ...       1   \n",
       "2    1   16  7.0  167581   754   143  1995          1    3     2 ...       1   \n",
       "3    4   44  NaN  445071  5705   604  1980          1    3     4 ...       1   \n",
       "4    4   43  6.0  436161  5645   592  1958          1    3     4 ...       4   \n",
       "\n",
       "   LN2_3  LN2_4  LN2_RIndLngBEOth  LN2_WIndLngBEOth   GN1  GN2  GN3  GN4  GN5  \n",
       "0      1      1               NaN               NaN  99.0   99   99   99   99  \n",
       "1      3      4           Bengali           Bengali   NaN    1    2    2    2  \n",
       "2      2      2             Hindi             Hindi   1.0    2    2    2    2  \n",
       "3      4      5             Tamil             Tamil   NaN    2    2   99   99  \n",
       "4      4      4         Malayalam         Malayalam   NaN    1    1    1    1  \n",
       "\n",
       "[5 rows x 421 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just kept 421 columns\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18255, 421)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a csv\n",
    "train.to_csv(PATH/\"train_421_cols.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking columns for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH/\"train_421_cols.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the label into another variable, dropping from main dataframe\n",
    "Y = train[\"is_female\"].values.astype(np.float32)\n",
    "X = train.drop(columns=[\"is_female\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling NAs and doing label encoding\n",
    "# Label encoding is simply converting each value in a column to a number (0 to num_classes).\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in X.columns:\n",
    "    if X.dtypes[col] == \"object\":\n",
    "        X[col] = X[col].fillna(\"NA\")\n",
    "    else:\n",
    "        X[col] = X[col].fillna(0)\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# telling pandas that all the variables are categorical\n",
    "for col in X.columns:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>DG4</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11369</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>424</td>\n",
       "      <td>482</td>\n",
       "      <td>252</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>410</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>310</td>\n",
       "      <td>166</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13476</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>664</td>\n",
       "      <td>564</td>\n",
       "      <td>300</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13406</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>587</td>\n",
       "      <td>111</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AA3 AA4 AA6  AA7 AA14 AA15 DG1 DG3 DG3A DG4 ... LN2_2 LN2_3 LN2_4  \\\n",
       "11369   1  10   2  424  482  252  62   2    3   4 ...     0     0     0   \n",
       "1250    2  17   1  831  831  410  63   2    3   5 ...     0     3     3   \n",
       "7527    1   8   0  301  310  166  53   2    3   0 ...     0     0     0   \n",
       "13476   2  14   2  664  564  300  69   2    3   4 ...     2     2     2   \n",
       "13406   0  12   3  587  111   76  58   2    3   2 ...     1     3     3   \n",
       "\n",
       "      LN2_RIndLngBEOth LN2_WIndLngBEOth GN1 GN2 GN3 GN4 GN5  \n",
       "11369               38               38   0   1   1   1   1  \n",
       "1250                33               32   1   2   2   0   0  \n",
       "7527                38               38   2   1   1   1   1  \n",
       "13476               14               14   3   2   2   2   2  \n",
       "13406               14               14   1   0   2   2   2  \n",
       "\n",
       "[5 rows x 420 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.20, random_state=3)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA3': 4,\n",
       " 'AA4': 22,\n",
       " 'AA6': 4,\n",
       " 'AA7': 1050,\n",
       " 'AA14': 907,\n",
       " 'AA15': 450,\n",
       " 'DG1': 79,\n",
       " 'DG3': 9,\n",
       " 'DG3A': 8,\n",
       " 'DG4': 12,\n",
       " 'DG6': 9,\n",
       " 'DG8a': 13,\n",
       " 'DG8b': 13,\n",
       " 'DG8c': 13,\n",
       " 'DG9a': 12,\n",
       " 'DG9b': 11,\n",
       " 'DG9c': 8,\n",
       " 'DG10b': 9,\n",
       " 'DG10c': 8,\n",
       " 'DG11b': 9,\n",
       " 'DL1': 12,\n",
       " 'DL2': 33,\n",
       " 'DL3': 3,\n",
       " 'DL5': 25,\n",
       " 'DL7': 3,\n",
       " 'DL8': 342,\n",
       " 'DL11': 15,\n",
       " 'DL14': 24,\n",
       " 'DL15': 4,\n",
       " 'DL24': 7,\n",
       " 'MT1': 13,\n",
       " 'MT1A': 8,\n",
       " 'MT3_1': 5,\n",
       " 'MT3_2': 6,\n",
       " 'MT3_3': 6,\n",
       " 'MT4_1': 3,\n",
       " 'MT4_2': 3,\n",
       " 'MT4_3': 3,\n",
       " 'MT4_4': 3,\n",
       " 'MT4_5': 3,\n",
       " 'MT4_6': 3,\n",
       " 'MT5': 8,\n",
       " 'MT6': 10,\n",
       " 'MT6A': 7,\n",
       " 'MT6B': 9,\n",
       " 'MT6C': 28,\n",
       " 'MT7': 3,\n",
       " 'MT11': 83,\n",
       " 'MT12_1': 5,\n",
       " 'MT12_2': 7,\n",
       " 'MT12_3': 6,\n",
       " 'MT12_4': 3,\n",
       " 'MT12_5': 3,\n",
       " 'MT12_7': 5,\n",
       " 'MT12_9': 3,\n",
       " 'MT12_11': 5,\n",
       " 'MT12_12': 3,\n",
       " 'MT12_13': 3,\n",
       " 'MT12_14': 3,\n",
       " 'MT14C_1': 5,\n",
       " 'MT14C_2': 5,\n",
       " 'MT14C_3': 5,\n",
       " 'MT14C_4': 5,\n",
       " 'MT15': 3,\n",
       " 'MT17_1': 7,\n",
       " 'MT17_2': 7,\n",
       " 'MT17_3': 7,\n",
       " 'MT17_4': 7,\n",
       " 'MT17_5': 7,\n",
       " 'MT17_6': 7,\n",
       " 'MT17_7': 7,\n",
       " 'MT17_8': 7,\n",
       " 'MT17_9': 7,\n",
       " 'MT17_10': 7,\n",
       " 'MT17_11': 7,\n",
       " 'MT17_12': 7,\n",
       " 'MT17_13': 7,\n",
       " 'MT18_1': 3,\n",
       " 'MT18_2': 3,\n",
       " 'MT18_3': 3,\n",
       " 'MT18_4': 3,\n",
       " 'MT18_5': 3,\n",
       " 'MT18_6': 3,\n",
       " 'MT18_96': 3,\n",
       " 'MT18_8': 3,\n",
       " 'FF2': 4,\n",
       " 'FF2A': 18,\n",
       " 'FF3': 27,\n",
       " 'FF4': 3,\n",
       " 'FF5': 4,\n",
       " 'FF6_1': 4,\n",
       " 'FF6_2': 4,\n",
       " 'FF6_3': 4,\n",
       " 'FF6_4': 4,\n",
       " 'FF6_5': 4,\n",
       " 'FF6_6': 4,\n",
       " 'FF6_7': 4,\n",
       " 'FF6_8': 4,\n",
       " 'FF6_9': 4,\n",
       " 'FF6_10': 4,\n",
       " 'FF7_1': 4,\n",
       " 'FF7_2': 4,\n",
       " 'FF7_4': 5,\n",
       " 'FF7_5': 4,\n",
       " 'FF7_6': 3,\n",
       " 'FF9': 7,\n",
       " 'FF10_1': 3,\n",
       " 'FF10_2': 3,\n",
       " 'FF10_3': 3,\n",
       " 'FF10_4': 3,\n",
       " 'FF10_5': 3,\n",
       " 'FF10_6': 3,\n",
       " 'FF10_96': 3,\n",
       " 'FF13': 8,\n",
       " 'FF14_1': 3,\n",
       " 'FF14_2': 3,\n",
       " 'FF14_3': 3,\n",
       " 'FF14_4': 3,\n",
       " 'FF14_5': 3,\n",
       " 'FF14_6': 3,\n",
       " 'FF14_7': 3,\n",
       " 'FF14_8': 3,\n",
       " 'FF14_9': 3,\n",
       " 'FF14_10': 3,\n",
       " 'FF14_11': 3,\n",
       " 'FF14_12': 3,\n",
       " 'FF14_13': 3,\n",
       " 'FF14_14': 3,\n",
       " 'FF14_15': 3,\n",
       " 'FF14_16': 3,\n",
       " 'FF14_17': 3,\n",
       " 'FF14_18': 3,\n",
       " 'FF14_19': 3,\n",
       " 'FF14_20': 3,\n",
       " 'FF14_21': 3,\n",
       " 'FF14_22': 3,\n",
       " 'FF14_23': 3,\n",
       " 'FF14_96': 3,\n",
       " 'FF16_1': 6,\n",
       " 'FF16_2': 6,\n",
       " 'FF19_1': 3,\n",
       " 'FF19_2': 3,\n",
       " 'FF19_3': 3,\n",
       " 'FF19_4': 3,\n",
       " 'FF19_5': 3,\n",
       " 'FF19_6': 3,\n",
       " 'FF19_7': 3,\n",
       " 'FF19_8': 3,\n",
       " 'MM3_1': 3,\n",
       " 'MM3_2': 3,\n",
       " 'MM3_3': 3,\n",
       " 'MM3_4': 3,\n",
       " 'MM3_5': 3,\n",
       " 'MM3_6': 3,\n",
       " 'MM3_7': 3,\n",
       " 'MM3_8': 3,\n",
       " 'MM3_9': 3,\n",
       " 'MM3_10': 3,\n",
       " 'MM3_11': 3,\n",
       " 'MM3_12': 3,\n",
       " 'MM3_13': 3,\n",
       " 'MM3_14': 3,\n",
       " 'IFI14_1': 7,\n",
       " 'IFI14_2': 7,\n",
       " 'IFI14_3': 7,\n",
       " 'IFI14_4': 7,\n",
       " 'IFI14_5': 7,\n",
       " 'IFI14_6': 7,\n",
       " 'IFI14_7': 7,\n",
       " 'IFI15_1': 7,\n",
       " 'IFI15_2': 7,\n",
       " 'IFI15_3': 7,\n",
       " 'IFI15_4': 7,\n",
       " 'IFI15_5': 7,\n",
       " 'IFI15_6': 7,\n",
       " 'IFI15_7': 7,\n",
       " 'IFI16_1': 11,\n",
       " 'IFI16_2': 11,\n",
       " 'IFI17_1': 7,\n",
       " 'IFI17_2': 7,\n",
       " 'IFI18': 9,\n",
       " 'IFI24': 12,\n",
       " 'FL1': 4,\n",
       " 'FL2': 5,\n",
       " 'FL3': 10,\n",
       " 'FL4': 19,\n",
       " 'FL7_1': 3,\n",
       " 'FL7_2': 3,\n",
       " 'FL7_3': 3,\n",
       " 'FL7_4': 3,\n",
       " 'FL7_5': 3,\n",
       " 'FL7_6': 3,\n",
       " 'FL8_1': 5,\n",
       " 'FL8_2': 5,\n",
       " 'FL8_3': 5,\n",
       " 'FL8_4': 5,\n",
       " 'FL8_5': 5,\n",
       " 'FL8_6': 5,\n",
       " 'FL8_7': 5,\n",
       " 'FL9A': 12,\n",
       " 'FL9B': 13,\n",
       " 'FL9C': 13,\n",
       " 'FL10': 13,\n",
       " 'FL11': 5,\n",
       " 'FL12': 3,\n",
       " 'FL14': 3,\n",
       " 'FL15': 4,\n",
       " 'FL16': 3,\n",
       " 'FL17': 3,\n",
       " 'FL18': 3,\n",
       " 'FB2': 3,\n",
       " 'FB13': 25,\n",
       " 'FB18': 5,\n",
       " 'FB19': 11,\n",
       " 'FB19B_1': 4,\n",
       " 'FB19B_2': 4,\n",
       " 'FB19B_3': 4,\n",
       " 'FB19B_4': 4,\n",
       " 'FB19B_5': 4,\n",
       " 'FB19B_96': 4,\n",
       " 'FB20': 16,\n",
       " 'FB24': 17,\n",
       " 'FB26_1': 3,\n",
       " 'FB26_2': 3,\n",
       " 'FB26_3': 3,\n",
       " 'FB26_4': 3,\n",
       " 'FB26_5': 3,\n",
       " 'FB26_6': 3,\n",
       " 'FB26_7': 3,\n",
       " 'FB26_8': 3,\n",
       " 'FB26_9': 3,\n",
       " 'FB26_10': 3,\n",
       " 'FB26_11': 3,\n",
       " 'FB26_96': 3,\n",
       " 'FB26_99': 3,\n",
       " 'LN1A': 4,\n",
       " 'LN1B': 4,\n",
       " 'LN2_1': 5,\n",
       " 'LN2_2': 5,\n",
       " 'LN2_3': 5,\n",
       " 'LN2_4': 5,\n",
       " 'LN2_RIndLngBEOth': 58,\n",
       " 'LN2_WIndLngBEOth': 59,\n",
       " 'GN1': 7,\n",
       " 'GN2': 6,\n",
       " 'GN3': 6,\n",
       " 'GN4': 6,\n",
       " 'GN5': 6}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables with two values are fine \n",
    "# number of values for variables with more than 2 values\n",
    "emb_c = {n: len(col.cat.categories) for n,col in X.items() if len(col.cat.categories) > 2}\n",
    "emb_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 2),\n",
       " (22, 11),\n",
       " (4, 2),\n",
       " (1050, 50),\n",
       " (907, 50),\n",
       " (450, 50),\n",
       " (79, 40),\n",
       " (9, 5),\n",
       " (8, 4),\n",
       " (12, 6),\n",
       " (9, 5),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (12, 6),\n",
       " (11, 6),\n",
       " (8, 4),\n",
       " (9, 5),\n",
       " (8, 4),\n",
       " (9, 5),\n",
       " (12, 6),\n",
       " (33, 17),\n",
       " (3, 2),\n",
       " (25, 13),\n",
       " (3, 2),\n",
       " (342, 50),\n",
       " (15, 8),\n",
       " (24, 12),\n",
       " (4, 2),\n",
       " (7, 4),\n",
       " (13, 7),\n",
       " (8, 4),\n",
       " (5, 3),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (8, 4),\n",
       " (10, 5),\n",
       " (7, 4),\n",
       " (9, 5),\n",
       " (28, 14),\n",
       " (3, 2),\n",
       " (83, 42),\n",
       " (5, 3),\n",
       " (7, 4),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (18, 9),\n",
       " (27, 14),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (4, 2),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (8, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (11, 6),\n",
       " (11, 6),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (9, 5),\n",
       " (12, 6),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (10, 5),\n",
       " (19, 10),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (12, 6),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (25, 13),\n",
       " (5, 3),\n",
       " (11, 6),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (16, 8),\n",
       " (17, 9),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (58, 29),\n",
       " (59, 30),\n",
       " (7, 4),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (6, 3)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the category, size of the embedding\n",
    "# 30 and (c+1)//2) are arbitrary (we should play with these numbers)\n",
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in emb_c.items()]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AA3', 'AA4', 'AA6', 'AA7', 'AA14', 'AA15', 'DG1', 'DG3', 'DG3A', 'DG4', 'DG6', 'DG8a', 'DG8b', 'DG8c', 'DG9a', 'DG9b', 'DG9c', 'DG10b', 'DG10c', 'DG11b', 'DL1', 'DL2', 'DL3', 'DL5', 'DL7', 'DL8', 'DL11', 'DL14', 'DL15', 'DL24', 'MT1', 'MT1A', 'MT3_1', 'MT3_2', 'MT3_3', 'MT4_1', 'MT4_2', 'MT4_3', 'MT4_4', 'MT4_5', 'MT4_6', 'MT5', 'MT6', 'MT6A', 'MT6B', 'MT6C', 'MT7', 'MT11', 'MT12_1', 'MT12_2', 'MT12_3', 'MT12_4', 'MT12_5', 'MT12_7', 'MT12_9', 'MT12_11', 'MT12_12', 'MT12_13', 'MT12_14', 'MT14C_1', 'MT14C_2', 'MT14C_3', 'MT14C_4', 'MT15', 'MT17_1', 'MT17_2', 'MT17_3', 'MT17_4', 'MT17_5', 'MT17_6', 'MT17_7', 'MT17_8', 'MT17_9', 'MT17_10', 'MT17_11', 'MT17_12', 'MT17_13', 'MT18_1', 'MT18_2', 'MT18_3', 'MT18_4', 'MT18_5', 'MT18_6', 'MT18_96', 'MT18_8', 'FF2', 'FF2A', 'FF3', 'FF4', 'FF5', 'FF6_1', 'FF6_2', 'FF6_3', 'FF6_4', 'FF6_5', 'FF6_6', 'FF6_7', 'FF6_8', 'FF6_9', 'FF6_10', 'FF7_1', 'FF7_2', 'FF7_4', 'FF7_5', 'FF7_6', 'FF9', 'FF10_1', 'FF10_2', 'FF10_3', 'FF10_4', 'FF10_5', 'FF10_6', 'FF10_96', 'FF13', 'FF14_1', 'FF14_2', 'FF14_3', 'FF14_4', 'FF14_5', 'FF14_6', 'FF14_7', 'FF14_8', 'FF14_9', 'FF14_10', 'FF14_11', 'FF14_12', 'FF14_13', 'FF14_14', 'FF14_15', 'FF14_16', 'FF14_17', 'FF14_18', 'FF14_19', 'FF14_20', 'FF14_21', 'FF14_22', 'FF14_23', 'FF14_96', 'FF16_1', 'FF16_2', 'FF19_1', 'FF19_2', 'FF19_3', 'FF19_4', 'FF19_5', 'FF19_6', 'FF19_7', 'FF19_8', 'MM3_1', 'MM3_2', 'MM3_3', 'MM3_4', 'MM3_5', 'MM3_6', 'MM3_7', 'MM3_8', 'MM3_9', 'MM3_10', 'MM3_11', 'MM3_12', 'MM3_13', 'MM3_14', 'IFI14_1', 'IFI14_2', 'IFI14_3', 'IFI14_4', 'IFI14_5', 'IFI14_6', 'IFI14_7', 'IFI15_1', 'IFI15_2', 'IFI15_3', 'IFI15_4', 'IFI15_5', 'IFI15_6', 'IFI15_7', 'IFI16_1', 'IFI16_2', 'IFI17_1', 'IFI17_2', 'IFI18', 'IFI24', 'FL1', 'FL2', 'FL3', 'FL4', 'FL7_1', 'FL7_2', 'FL7_3', 'FL7_4', 'FL7_5', 'FL7_6', 'FL8_1', 'FL8_2', 'FL8_3', 'FL8_4', 'FL8_5', 'FL8_6', 'FL8_7', 'FL9A', 'FL9B', 'FL9C', 'FL10', 'FL11', 'FL12', 'FL14', 'FL15', 'FL16', 'FL17', 'FL18', 'FB2', 'FB13', 'FB18', 'FB19', 'FB19B_1', 'FB19B_2', 'FB19B_3', 'FB19B_4', 'FB19B_5', 'FB19B_96', 'FB20', 'FB24', 'FB26_1', 'FB26_2', 'FB26_3', 'FB26_4', 'FB26_5', 'FB26_6', 'FB26_7', 'FB26_8', 'FB26_9', 'FB26_10', 'FB26_11', 'FB26_96', 'FB26_99', 'LN1A', 'LN1B', 'LN2_1', 'LN2_2', 'LN2_3', 'LN2_4', 'LN2_RIndLngBEOth', 'LN2_WIndLngBEOth', 'GN1', 'GN2', 'GN3', 'GN4', 'GN5'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_cols = emb_c.keys()\n",
    "emb_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Dataset is a custom class to conveniently interact with a set observations. Designing this Dataset class is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all variables are categorical, but some of them has just two values \n",
    "# emb_c are the variables we plan to embed\n",
    "class WiDSDataset(Dataset):\n",
    "    def __init__(self, X, Y, emb_cols):\n",
    "        X = X.copy()\n",
    "        # splitting categorical columns and numerical columns\n",
    "        self.X1 = X.loc[:,emb_cols].copy().values.astype(np.int64)\n",
    "        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32)\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X1[idx], self.X2[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = WiDSDataset(X_train, y_train, emb_cols)\n",
    "valid_ds = WiDSDataset(X_val, y_val, emb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0,   4,   3, 200, 229, 129,  72,   0,   3,   5,   2,   5,   3,\n",
       "          1,   3,   0,   0,   3,   0,   3,   5,   0,   0,   0,   1, 136,\n",
       "          0,   8,   3,   0,   1,   7,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   1,   2,   0,   0,   1,   3,\n",
       "          1,   3,   2,   1,   2,   3,   2,   2,   2,   0,   0,   1,   0,\n",
       "          0,   4,   1,   2,   2,   2,   2,   2,   2,   1,   1,   1,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   4,   4,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   0,   2,   2,   6,   6,   6,   6,   6,   6,\n",
       "          1,   6,   6,   6,   6,   6,   6,   6,   0,   1,   0,   8,   0,\n",
       "          3,   0,   0,   7,   1,   1,   1,   1,   1,   1,   1,   3,   2,\n",
       "          1,   1,   3,   2,  10,   0,   0,   0,   1,   0,   0,   0,   1,\n",
       "          0,   0,   1,  24,   4,   9,   3,   2,   2,   2,   2,   2,  15,\n",
       "          0,   2,   2,   2,   2,   1,   1,   1,   1,   2,   2,   1,   2,\n",
       "          2,   1,   1,   0,   0,   3,   3,  14,  14,   0,   2,   2,   3,\n",
       "          2]),\n",
       " array([0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], dtype=float32),\n",
       " 0.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from fast.ai\n",
    "class MixedInputModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embs) \n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 100)\n",
    "        self.lin2 = nn.Linear(100, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.emb_drop = nn.Dropout(0.5)\n",
    "        self.drops = nn.Dropout(0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 248]) torch.Size([5, 172]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "x1, x2, y = next(iter(train_dl))\n",
    "print(x1.shape, x2.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2586],\n",
       "        [-0.1512],\n",
       "        [-0.3504],\n",
       "        [ 0.4256],\n",
       "        [-0.1495]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.unsqueeze(1)\n",
    "out = model(x1, x2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (out > 0.0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred == y).float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6818)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy_with_logits(out, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, train_dl=train_dl, verbose=False):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for i, (x1, x2, y) in enumerate(train_dl):\n",
    "        batch = y.shape[0]\n",
    "        y = y.unsqueeze(1)  \n",
    "        out = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "        if verbose: print(sum_loss/total)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x1, x2, y in valid_dl:\n",
    "        batch = y.shape[0]\n",
    "        y = y.unsqueeze(1)\n",
    "        out = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "        pred = (out > 0).float()\n",
    "        correct += (pred == y).float().sum().item()\n",
    "    print(\"val loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def train_loop(model, epochs, lr=0.01, wd=0.0):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optim, train_dl)\n",
    "        print(\"loss \", loss)\n",
    "        val_loss(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedInputModel(emb_szs, 172) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the higest learning rate that doesn't cycle \n",
    "#optim = get_optimizer(model, lr = 0.1, wd = 0.0)\n",
    "#train_model(model, optim, train_dl, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  0.41737512909069807\n",
      "val loss 0.299 and accuracy 0.872\n",
      "loss  0.27698620407344937\n",
      "val loss 0.246 and accuracy 0.902\n",
      "loss  0.2440781471819722\n",
      "val loss 0.242 and accuracy 0.902\n",
      "loss  0.22910210879183376\n",
      "val loss 0.241 and accuracy 0.901\n",
      "loss  0.22360518508187976\n",
      "val loss 0.247 and accuracy 0.904\n",
      "loss  0.2099693892663944\n",
      "val loss 0.254 and accuracy 0.898\n",
      "loss  0.20640635142682906\n",
      "val loss 0.263 and accuracy 0.895\n",
      "loss  0.2044702067632474\n",
      "val loss 0.266 and accuracy 0.893\n",
      "loss  0.19647855688140542\n",
      "val loss 0.258 and accuracy 0.901\n",
      "loss  0.19534300517477554\n",
      "val loss 0.269 and accuracy 0.896\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, epochs=10, lr=0.05, wd=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate (LR) range test\n",
    "The [learning rate range test](https://arxiv.org/abs/1506.01186) is a way to estimate minimum and maximum boundary values for learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))\n",
    "\n",
    "def LR_range_finder(model, train_dl, lr_low=1e-5, lr_high=1, epochs=2):\n",
    "    losses = []\n",
    "    p = PATH/\"mode_tmp.pth\"\n",
    "    save_model(model, str(p))\n",
    "    iterations = epochs * len(train_dl)\n",
    "    delta = (lr_high - lr_low)/iterations\n",
    "    lrs = [lr_low + i*delta for i in range(iterations)]\n",
    "    model.train()\n",
    "    ind = 0\n",
    "    for i in range(epochs):\n",
    "        for j, (x1, x2, y) in enumerate(train_dl):\n",
    "            # changing learning rate at each iteration\n",
    "            optim = get_optimizer(model, lr=lrs[ind])\n",
    "            batch = y.shape[0]\n",
    "            y = y.unsqueeze(1)  \n",
    "            out = model(x1, x2)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y)   \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            losses.append(loss.item())\n",
    "            ind +=1\n",
    "            \n",
    "    load_model(model, str(p))\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_low, lr_high and batch_size are important so that the plot gives\n",
    "# useful information\n",
    "lrs, losses = LR_range_finder(model, train_dl, lr_low=1e-5, lr_high=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the lower boundary as the value of the learning rate when the loss starts to decrease. Pick the upper learning rate when the loss slows, becomes ragged or increases. From this graph I would try $base\\_lr=1e-5$ and $max\\_lr=0.075$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One cycle learning rate policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triangular_lr2(lr_low, lr_high, iterations):\n",
    "    iter1 = int(0.35*iterations)\n",
    "    iter2 = int(0.85*iter1)\n",
    "    iter3 = iterations - iter1 - iter2\n",
    "    delta1 = (lr_high - lr_low)/iter1\n",
    "    delta2 = (lr_high - lr_low)/(iter1 -1)\n",
    "    lrs1 = [lr_low + i*delta1 for i in range(iter1)]\n",
    "    lrs2 = [lr_high - i*(delta1) for i in range(0, iter2)]\n",
    "    delta2 = (lrs2[-1] - lr_low)/(iter3)\n",
    "    lrs3 = [lrs2[-1] - i*(delta2) for i in range(1, iter3+1)]\n",
    "    return lrs1+lrs2+lrs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = get_triangular_lr2(1e-5, 0.1, 1000)\n",
    "plt.plot(lrs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triangular_policy(model, train_dl, valid_dl, lr_low=1e-5, lr_high=0.01, epochs=4):\n",
    "    idx = 0\n",
    "    iterations = epochs*len(train_dl)\n",
    "    lrs = get_triangular_lr2(lr_low, lr_high, iterations)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for i, (x1, x2, y) in enumerate(train_dl):\n",
    "            optim = get_optimizer(model, lr = lrs[idx], wd = 0.00001)\n",
    "            batch = y.shape[0]\n",
    "            y = y.unsqueeze(1)  \n",
    "            out = model(x1, x2)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y) \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            idx += 1\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        print(\"train loss\", sum_loss/total)\n",
    "        val_loss(model, valid_dl)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a new model\n",
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.46538881297569934\n",
      "val loss 0.338 and accuracy 0.864\n",
      "train loss 0.34969842749012886\n",
      "val loss 0.331 and accuracy 0.857\n",
      "train loss 0.3401990460389544\n",
      "val loss 0.307 and accuracy 0.881\n",
      "train loss 0.36807284266842255\n",
      "val loss 0.258 and accuracy 0.895\n",
      "train loss 0.3199115289919542\n",
      "val loss 0.305 and accuracy 0.870\n",
      "train loss 0.27405895681307435\n",
      "val loss 0.245 and accuracy 0.900\n"
     ]
    }
   ],
   "source": [
    "train_triangular_policy(model, train_dl, valid_dl, lr_low=1e-6, lr_high=0.08, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get a better validation score by hyper-parameter tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
